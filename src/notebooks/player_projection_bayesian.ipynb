{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4ab1a2",
   "metadata": {},
   "source": [
    "# NFL Fantasy Football Projection Model Using XGBoost\n",
    "\n",
    "This notebook presents a comprehensive workflow for building an NFL fantasy football projection model using a Bayesian Method. Data sources include Yahoo, Pro-Football Reference, SportsDataIO, and NFLVerse. The goal is to leverage advanced machine learning techniques and rich datasets to generate accurate player projections for fantasy football analysis and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5313a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: c:\\Users\\bengu\\Documents\\NFL Data Project\\clairvoyent-raven-sports-analysis\\src\n",
      "Sys Path Before: ['C:\\\\Users\\\\bengu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\python310.zip', 'C:\\\\Users\\\\bengu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\DLLs', 'C:\\\\Users\\\\bengu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib', 'C:\\\\Users\\\\bengu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj', '', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj\\\\lib\\\\site-packages', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj\\\\lib\\\\site-packages\\\\Pythonwin']\n",
      "Inserting project root to sys.path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pymc as pm\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(\"Sys Path Before:\", sys.path)\n",
    "if project_root not in sys.path:\n",
    "    print(\"Inserting project root to sys.path\")\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Now import\n",
    "from data_api import SportsDataIO, Yahoo, PFR\n",
    "import utils\n",
    "import yahoo_helpers\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1806398",
   "metadata": {},
   "source": [
    "## Import and clean data from nflverse source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbca551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFLVERSE_DATA_PATH = r\"C:\\Users\\bengu\\Documents\\Sports Analysis Project\\clairvoyent-raven-sports-analysis\\data\\nfl_player_stats_cleaned.csv\"\n",
    "NFLVERSE_TEAMS_DATA_PATH = r\"C:\\Users\\bengu\\Documents\\Sports Analysis Project\\clairvoyent-raven-sports-analysis\\data\\nfl_team_stats.xlsx\"\n",
    "NFLVERSE_INJURIES_PATH = r\"C:\\Users\\bengu\\Documents\\Sports Analysis Project\\clairvoyent-raven-sports-analysis\\data\\nfl_injuries.xlsx\"\n",
    "\n",
    "all_players_df = pd.read_csv(NFLVERSE_DATA_PATH)\n",
    "all_teams_df = pd.read_excel(NFLVERSE_TEAMS_DATA_PATH, engine=\"openpyxl\")\n",
    "injuries_df = pd.read_excel(NFLVERSE_INJURIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7775d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_categories = {\n",
    "    \"standard\": {\n",
    "        \"player_id\",\n",
    "        \"player_name\",\n",
    "        \"position\",\n",
    "        \"position_group\",\n",
    "        \"season\",\n",
    "        \"week\",\n",
    "        \"season_type\",\n",
    "        \"team\",\n",
    "        \"opponent_team\",\n",
    "        \"pacr\",\n",
    "    },\n",
    "    \"passing\": {\n",
    "        \"completions\",\n",
    "        \"attempts\",\n",
    "        \"passing_yards\",\n",
    "        \"passing_tds\",\n",
    "        \"passing_interceptions\",\n",
    "        \"sacks_suffered\",\n",
    "        \"sack_yards_lost\",\n",
    "        \"sack_fumbles\",\n",
    "        \"sack_fumbles_lost\",\n",
    "        \"passing_air_yards\",\n",
    "        \"passing_yards_after_catch\",\n",
    "        \"passing_first_downs\",\n",
    "        \"passing_epa\",\n",
    "        \"passing_cpoe\",\n",
    "        \"passing_2pt_conversions\",\n",
    "        \"carries\", # Include rushing stats for QBs\n",
    "        \"rushing_yards\",\n",
    "        \"rushing_tds\",\n",
    "        \"rushing_fumbles\",\n",
    "        \"rushing_fumbles_lost\",\n",
    "        \"rushing_first_downs\",\n",
    "        \"rushing_epa\",\n",
    "        \"rushing_2pt_conversions\",\n",
    "    },\n",
    "    \"rushing_and_receiving\": {\n",
    "        \"carries\",\n",
    "        \"rushing_yards\",\n",
    "        \"rushing_tds\",\n",
    "        \"rushing_fumbles\",\n",
    "        \"rushing_fumbles_lost\",\n",
    "        \"rushing_first_downs\",\n",
    "        \"rushing_epa\",\n",
    "        \"rushing_2pt_conversions\",\n",
    "        \"receptions\",\n",
    "        \"targets\",\n",
    "        \"receiving_yards\",\n",
    "        \"receiving_tds\",\n",
    "        \"receiving_fumbles\",\n",
    "        \"receiving_fumbles_lost\",\n",
    "        \"receiving_air_yards\",\n",
    "        \"receiving_yards_after_catch\",\n",
    "        \"receiving_first_downs\",\n",
    "        \"rushing_epa\",\n",
    "        \"rushing_2pt_conversions\",\n",
    "        \"receptions\",\n",
    "        \"targets\",\n",
    "        \"receiving_yards\",\n",
    "        \"receiving_tds\",\n",
    "        \"receiving_fumbles\",\n",
    "        \"receiving_fumbles_lost\",\n",
    "        \"receiving_air_yards\",\n",
    "        \"receiving_yards_after_catch\",\n",
    "        \"receiving_first_downs\",\n",
    "        \"receiving_epa\",\n",
    "        \"receiving_2pt_conversions\",\n",
    "        \"racr\",\n",
    "        \"target_share\",\n",
    "        \"air_yards_share\",\n",
    "        \"wopr\",\n",
    "    },\n",
    "    \"defense\": {\n",
    "        \"special_teams_tds\",\n",
    "        \"def_tackles_solo\",\n",
    "        \"def_tackles_with_assist\",\n",
    "        \"def_tackle_assists\",\n",
    "        \"def_tackles_for_loss\",\n",
    "        \"def_tackles_for_loss_yards\",\n",
    "        \"def_fumbles_forced\",\n",
    "        \"def_sacks\",\n",
    "        \"def_sack_yards\",\n",
    "        \"def_qb_hits\",\n",
    "        \"def_interceptions\",\n",
    "        \"def_interception_yards\",\n",
    "        \"def_pass_defended\",\n",
    "        \"def_tds\",\n",
    "        \"def_fumbles\",\n",
    "        \"def_safeties\",\n",
    "        \"misc_yards\",\n",
    "        \"fumble_recovery_own\",\n",
    "        \"fumble_recovery_yards_own\",\n",
    "        \"fumble_recovery_opp\",\n",
    "        \"fumble_recovery_yards_opp\",\n",
    "        \"fumble_recovery_tds\",\n",
    "        \"penalties\",\n",
    "    },\n",
    "    \"kicking\": {\n",
    "        \"fg_made\",\n",
    "        \"fg_att\",\n",
    "        \"fg_missed\",\n",
    "        \"fg_blocked\",\n",
    "        \"fg_long\",\n",
    "        \"fg_pct\",\n",
    "        \"fg_made_0_19\",\n",
    "        \"fg_made_20_29\",\n",
    "        \"fg_made_30_39\",\n",
    "        \"fg_made_40_49\",\n",
    "        \"fg_made_50_59\",\n",
    "        \"fg_made_60_\",\n",
    "        \"fg_missed_0_19\",\n",
    "        \"fg_missed_20_29\",\n",
    "        \"fg_missed_30_39\",\n",
    "        \"fg_missed_40_49\",\n",
    "        \"fg_missed_50_59\",\n",
    "        \"fg_missed_60_\",\n",
    "        \"fg_made_list\",\n",
    "        \"fg_missed_list\",\n",
    "        \"fg_blocked_list\",\n",
    "        \"fg_made_distance\",\n",
    "        \"fg_missed_distance\",\n",
    "        \"fg_blocked_distance\",\n",
    "        \"pat_made\",\n",
    "        \"pat_att\",\n",
    "        \"pat_missed\",\n",
    "        \"pat_blocked\",\n",
    "        \"pat_pct\",\n",
    "        \"gwfg_made\",\n",
    "        \"gwfg_att\",\n",
    "        \"gwfg_missed\",\n",
    "        \"gwfg_blocked\",\n",
    "        \"gwfg_distance\",\n",
    "    },\n",
    "    \"special_teams\": {\n",
    "        \"punt_returns\",\n",
    "        \"punt_return_yards\",\n",
    "        \"kickoff_returns\",\n",
    "        \"kickoff_return_yards\",\n",
    "    },\n",
    "}\n",
    "\n",
    "categories_positions = {\n",
    "    \"passing\": [\"QB\"],\n",
    "    \"rushing_and_receiving\": [\"RB\", \"WR\"],\n",
    "    # Not available \"kicking\": [\"K\"] \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f56736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish dataframes for each positional group, filter by position value\n",
    "def filter_by_positional_group(df, category_key_a, category_key_b=\"standard\") -> pd.DataFrame:\n",
    "    new_df = df.loc[:, list(column_categories[category_key_a] | column_categories[category_key_b])]\n",
    "    new_df = new_df[new_df[\"position\"].isin(categories_positions[category_key_a])]\n",
    "    return new_df.reset_index(drop=True)\n",
    "\n",
    "# Data of interest\n",
    "passing_df = filter_by_positional_group(all_players_df, \"passing\")\n",
    "rushing_and_receiving_df = filter_by_positional_group(all_players_df, \"rushing_and_receiving\")\n",
    "\n",
    "# Save in case\n",
    "defense_df = all_players_df.loc[:, list(column_categories[\"standard\"] | column_categories[\"defense\"])]\n",
    "kicking_df = all_players_df.loc[:, list(column_categories[\"standard\"] | column_categories[\"kicking\"])]\n",
    "specials_teams_df = all_players_df.loc[:, list(column_categories[\"standard\"] | column_categories[\"special_teams\"])]\n",
    "\n",
    "# Give the dataframes each an alias\n",
    "passing_df.alias = \"passing_df\"\n",
    "rushing_and_receiving_df.alias = \"rushing_and_receiving_df\"\n",
    "defense_df.alias = \"defense_df\"\n",
    "kicking_df.alias = \"kicking_df\"\n",
    "specials_teams_df.alias = \"specials_teams_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1c018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking passing_df for null values\n",
      "passing_df contains 0 null values.\n",
      "Checking rushing_and_receiving_df for null values\n",
      "rushing_and_receiving_df contains 0 null values.\n",
      "Checking defense_df for null values\n",
      "defense_df contains 0 null values.\n",
      "Checking kicking_df for null values\n",
      "kicking_df contains 0 null values.\n",
      "Checking specials_teams_df for null values\n",
      "specials_teams_df contains 0 null values.\n"
     ]
    }
   ],
   "source": [
    "for df in [passing_df, rushing_and_receiving_df, defense_df, kicking_df, specials_teams_df]:\n",
    "    null_values = 0\n",
    "    print(f\"Checking {df.alias} for null values\")\n",
    "    null_counts = df.isna().sum()\n",
    "\n",
    "    for column, count in zip(null_counts.index, null_counts):\n",
    "        if count != 0:\n",
    "            null_values += 1\n",
    "            print(f\"Column: {column} contains {count} null values.\")\n",
    "    \n",
    "    print(f\"{df.alias} contains {null_values} null values.\")\n",
    "\n",
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2840d92",
   "metadata": {},
   "source": [
    "### Implement and Apply Model\n",
    "\n",
    "Implement multiple linear regression models to predict multiple statistics for rushers and receivers. \n",
    "\n",
    "* Define the targets: rushing_yards, rushing_tds, receiving_yards, receiving_tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e81076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pacr', 'player_id', 'opponent_team', 'receiving_epa',\n",
       "       'rushing_fumbles', 'target_share', 'rushing_yards', 'carries',\n",
       "       'rushing_fumbles_lost', 'position_group', 'team', 'racr',\n",
       "       'receiving_yards', 'receptions', 'receiving_yards_after_catch',\n",
       "       'receiving_tds', 'season', 'receiving_fumbles', 'wopr',\n",
       "       'receiving_first_downs', 'rushing_2pt_conversions',\n",
       "       'receiving_air_yards', 'week', 'rushing_epa', 'position',\n",
       "       'air_yards_share', 'season_type', 'targets', 'rushing_first_downs',\n",
       "       'rushing_tds', 'receiving_fumbles_lost', 'receiving_2pt_conversions',\n",
       "       'player_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rushing_and_receiving_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68947e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect xs, and ys.\n",
    "Normalize data using Z-score normalization\n",
    "(val - mean_val) / standard_deviation\n",
    "\n",
    "Create 4 buckets, one for each statistical category.\n",
    "\n",
    "Prefix   | Stat Category\n",
    "-------------------------\n",
    "rsh_yd_ -> rushing_yards\n",
    "rsh_td_ -> rushing_tds\n",
    "rc_yd_  -> receiving_yards\n",
    "rc_td_  -> receiving_tds\n",
    "\"\"\"\n",
    "\n",
    "inputs = {\n",
    "    \"rsh_yd\": [\"rushing_tds\", \"rushing_yards\", \"rushing_fumbles_lost\", \"racr\", \"rushing_epa\", \"rushing_fumbles\", \"carries\", \"pacr\", \"rushing_first_downs\", \"rushing_2pt_conversions\"],\n",
    "    \"rsh_td\": [\"rushing_tds\", \"rushing_yards\", \"rushing_fumbles_lost\", \"racr\", \"rushing_epa\", \"rushing_fumbles\", \"carries\", \"pacr\", \"rushing_first_downs\", \"rushing_2pt_conversions\"],\n",
    "    \"rc_yd\" : [\"receiving_epa\", \"receiving_2pt_conversions\", \"racr\", \"air_yards_share\", \"receiving_tds\", \"receiving_first_downs\", \"wopr\", \"receiving_yards_after_catch\", \"receiving_air_yards\", \"target_share\", \"pacr\", \"targets\", \"receiving_yards\",  \"receiving_fumbles_lost\", \"receptions\"],\n",
    "    \"rc_td\" : [\"receiving_epa\", \"receiving_2pt_conversions\", \"racr\", \"air_yards_share\", \"receiving_tds\", \"receiving_first_downs\", \"wopr\", \"receiving_yards_after_catch\", \"receiving_air_yards\", \"target_share\", \"pacr\", \"targets\", \"receiving_yards\",  \"receiving_fumbles_lost\", \"receptions\"],\n",
    "    \"def\": [\"def_tackles_solo\", \"def_tackles_with_assist\", \"def_tackle_assists\", \"def_tackles_for_loss\", \"def_tackles_for_loss_yards\", \"def_fumbles_forced\", \"def_sacks\", \"def_sack_yards\", \"def_qb_hits\", \"def_interceptions\", \"def_interception_yards\", \"def_pass_defended\", \"def_tds\", \"def_fumbles\", \"def_safeties\"]\n",
    "\n",
    "}\n",
    "\n",
    "# Stat 1 rushing_yards\n",
    "rsh_yd_X = rushing_and_receiving_df[inputs[\"rsh_yd\"] + [\"season\", \"week\", \"player_id\", \"opponent_team\"]]\n",
    "# Stat 2 rushing_tds\n",
    "rsh_td_X = rushing_and_receiving_df[inputs[\"rsh_td\"] + [\"season\", \"week\", \"player_id\", \"opponent_team\"]]\n",
    "# Stat 3 receiving_yards\n",
    "rc_yd_X = rushing_and_receiving_df[inputs[\"rc_yd\"] + [\"season\", \"week\", \"player_id\", \"opponent_team\"]]\n",
    "# Stat 4 receiving_tds\n",
    "rc_td_X = rushing_and_receiving_df[inputs[\"rc_td\"] + [\"season\", \"week\", \"player_id\", \"opponent_team\"]]\n",
    "\n",
    "# Defensive stats for opponent\n",
    "defense_stats_df = all_teams_df[inputs[\"def\"] + [\"season\", \"week\", \"team\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeddce7",
   "metadata": {},
   "source": [
    "Calculate rolling data over a period of 3 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e3ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_data(df: pd.DataFrame, sort_values: list, input_ref: str, groupby: list, rolling_period: int=3, min_periods: int=1, shift: int=1):\n",
    "    df = df.sort_values(sort_values)\n",
    "\n",
    "    df[[f\"{c}_roll{rolling_period}_shift\" for c in inputs[input_ref]]] = (\n",
    "        df.groupby(groupby)[inputs[input_ref]]\n",
    "         .transform(lambda x: x.rolling(rolling_period, min_periods=min_periods).mean().shift(shift))\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "rsh_yd_X = calculate_rolling_data(rsh_yd_X, [\"season\", \"week\", \"player_id\"], \"rsh_yd\", [\"season\", \"player_id\"])\n",
    "rsh_td_X = calculate_rolling_data(rsh_td_X, [\"season\", \"week\", \"player_id\"], \"rsh_td\", [\"season\", \"player_id\"])\n",
    "rc_yd_X = calculate_rolling_data(rc_yd_X, [\"season\", \"week\", \"player_id\"], \"rc_yd\", [\"season\", \"player_id\"])\n",
    "rc_td_X = calculate_rolling_data(rc_td_X, [\"season\", \"week\", \"player_id\"], \"rc_td\", [\"season\", \"player_id\"])\n",
    "defense_stats_df = calculate_rolling_data(defense_stats_df, [\"season\", \"week\", \"team\"], \"def\", [\"season\", \"team\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d507348f",
   "metadata": {},
   "source": [
    "Normalize the data using Z-Score Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55348b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Z-Score Standardization (sklearn StandardScaler)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "rsh_yd_input_cols = [col + \"_roll3_shift\" for col in inputs[\"rsh_yd\"]]\n",
    "rsh_td_input_cols = [col + \"_roll3_shift\" for col in inputs[\"rsh_td\"]]\n",
    "rc_yd_input_cols = [col + \"_roll3_shift\" for col in inputs[\"rc_yd\"]]\n",
    "rc_td_input_cols = [col + \"_roll3_shift\" for col in inputs[\"rc_td\"]]\n",
    "def_input_cols = [col + \"_roll3_shift\" for col in inputs[\"def\"]]\n",
    "scalers = {}\n",
    "\n",
    "def scale_inplace(df, cols, name):\n",
    "    # optionally: df = df.copy()  # if you want to avoid mutating the original\n",
    "    scaler = StandardScaler()\n",
    "    df.loc[:, cols] = scaler.fit_transform(df[cols])\n",
    "    scalers[name] = scaler\n",
    "    return df\n",
    "\n",
    "rsh_yd_X = scale_inplace(rsh_yd_X, rsh_yd_input_cols, \"rsh_yd\")\n",
    "rsh_td_X = scale_inplace(rsh_td_X, rsh_td_input_cols, \"rsh_td\")\n",
    "rc_yd_X  = scale_inplace(rc_yd_X,  rc_yd_input_cols,  \"rc_yd\")\n",
    "rc_td_X  = scale_inplace(rc_td_X,  rc_td_input_cols,  \"rc_td\")\n",
    "defense_stats_df = scale_inplace(defense_stats_df, def_input_cols, \"def\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c71a4",
   "metadata": {},
   "source": [
    "Merge offense and defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff7568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the defensive dataframe to the offensive one.\n",
    "rsh_yd_X = rsh_yd_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"]).dropna().reset_index(drop=True)\n",
    "rsh_td_X = rsh_td_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"]).dropna().reset_index(drop=True)\n",
    "rc_yd_X = rc_yd_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"]).dropna().reset_index(drop=True)\n",
    "rc_td_X = rc_td_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"]).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88debd",
   "metadata": {},
   "source": [
    "### Apply the Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77e7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 536 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 677 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 860 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 876 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\"\"\"\n",
    "Build the model to project player yards for rushing and receiving.\n",
    "\"\"\"\n",
    "# df: one row per (player, week)\n",
    "# y = yards (float)\n",
    "# X = scaled features (numpy array), shape (n, p)\n",
    "\n",
    "def fit_bayesian_model(X, y):\n",
    "    with pm.Model() as model:\n",
    "        alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "        beta = pm.Normal(\"beta\", 0, 1, shape=X.shape[1])\n",
    "        sigma = pm.HalfNormal(\"sigma\", 1)\n",
    "\n",
    "        mu = alpha + pm.math.dot(X, beta)\n",
    "        y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y)\n",
    "\n",
    "        idata = pm.sample()\n",
    "        return model, y_obs, idata\n",
    "    \n",
    "def predict_from_fitted(idata, X_new, predictive=True, ci=(5, 95), seed=0):\n",
    "    \"\"\"\n",
    "    Make predictions from your fitted Bayesian regression model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    idata : arviz.InferenceData\n",
    "        The posterior samples returned by pm.sample().\n",
    "    X_new : array-like of shape (n, p)\n",
    "        New feature matrix (must be scaled and ordered like training X).\n",
    "    predictive : bool\n",
    "        If True, return posterior predictive (includes noise).\n",
    "        If False, return posterior mean function (no added noise).\n",
    "    ci : tuple\n",
    "        Credible interval percentiles (default 90% CI).\n",
    "    seed : int\n",
    "        Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    Xn = np.asarray(X_new, dtype=float)\n",
    "\n",
    "    post = idata.posterior\n",
    "    alpha = post[\"alpha\"].values.reshape(-1)                  # (S,)\n",
    "    beta  = post[\"beta\"].values.reshape(-1, Xn.shape[1])      # (S, p)\n",
    "    sigma = post[\"sigma\"].values.reshape(-1)                  # (S,)\n",
    "\n",
    "    # Compute linear mean function draws (S,n)\n",
    "    mu_draws = beta @ Xn.T + alpha[:, None]\n",
    "\n",
    "    if predictive:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        y_draws = mu_draws + rng.normal(0.0, sigma[:, None], size=mu_draws.shape)\n",
    "    else:\n",
    "        y_draws = mu_draws\n",
    "\n",
    "    # Summaries\n",
    "    pred_mean   = y_draws.mean(axis=0)\n",
    "    pred_median = np.median(y_draws, axis=0)\n",
    "    lo, hi      = np.percentile(y_draws, ci, axis=0)\n",
    "\n",
    "    return pred_mean, pred_median, (lo, hi), y_draws\n",
    "\n",
    "model_results = {}\n",
    "idatas = {}\n",
    "models = {}\n",
    "\n",
    "input_dataframes = [rsh_yd_X, rsh_td_X, rc_yd_X, rc_td_X]\n",
    "inputs = [rsh_yd_input_cols, rsh_td_input_cols, rc_yd_input_cols, rc_td_input_cols]\n",
    "targets = [\"rushing_yards\", \"rushing_tds\", \"receiving_yards\", \"receiving_tds\"]\n",
    "\n",
    "for df, input, target in zip(input_dataframes, inputs, targets):\n",
    "    X = df.dropna()[input + def_input_cols].reset_index(drop=True)\n",
    "    y = df.dropna()[target].reset_index(drop=True)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model, y_obs, idata = fit_bayesian_model(X_train, y_train)\n",
    "\n",
    "    models[target] = model \n",
    "    idatas[target] = idata\n",
    "\n",
    "    pred_mean, pred_median, (pred_lo, pred_hi), y_draws = predict_from_fitted(idata, X)\n",
    "\n",
    "    # using mean\n",
    "    rmse_mean = root_mean_squared_error(y, pred_mean)\n",
    "    r2_mean = r2_score(y, pred_mean)\n",
    "\n",
    "    # using median\n",
    "    rmse_median = root_mean_squared_error(y, pred_median)\n",
    "    r2_median = r2_score(y, pred_median)    \n",
    "\n",
    "    # using lo\n",
    "    rmse_lo = root_mean_squared_error(y, pred_lo)\n",
    "    r2_lo = r2_score(y, pred_lo)\n",
    "\n",
    "    #using hi\n",
    "    rmse_hi = root_mean_squared_error(y, pred_hi)\n",
    "    r2_hi = r2_score(y, pred_hi)\n",
    "\n",
    "    model_results[target] = {\"mean\": {\"rmse\": rmse_mean, \"r2\": r2_mean}, \"median\": {\"rmse\": rmse_median, \"r2\": r2_median}, \"low\": {\"rmse\": rmse_lo, \"r2\": r2_lo}, \"high\": {\"rmse\": rmse_hi, \"r2\": r2_hi}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2668f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rushing_yards': {'mean': {'rmse': 19.5359052923446,\n",
       "   'r2': 0.5790976735681309},\n",
       "  'median': {'rmse': 19.53894409873511, 'r2': 0.5789667208288062},\n",
       "  'low': {'rmse': 37.69797531954284, 'r2': -0.5672933660924246},\n",
       "  'high': {'rmse': 37.52061382545411, 'r2': -0.5525804497482674}},\n",
       " 'rushing_tds': {'mean': {'rmse': 0.3256196176737835,\n",
       "   'r2': 0.2067094709424091},\n",
       "  'median': {'rmse': 0.32564604213954723, 'r2': 0.20658071255165888},\n",
       "  'low': {'rmse': 0.6282869660546823, 'r2': -1.9534338344964062},\n",
       "  'high': {'rmse': 0.6294415133963421, 'r2': -1.9642983355392465}},\n",
       " 'receiving_yards': {'mean': {'rmse': 26.99626348702199,\n",
       "   'r2': 0.3522062139624331},\n",
       "  'median': {'rmse': 26.99913663246148, 'r2': 0.35206832044952274},\n",
       "  'low': {'rmse': 52.08103413888254, 'r2': -1.4109525299656456},\n",
       "  'high': {'rmse': 51.73018801767431, 'r2': -1.378578971089281}},\n",
       " 'receiving_tds': {'mean': {'rmse': 0.3936778254723125,\n",
       "   'r2': 0.10026471347098087},\n",
       "  'median': {'rmse': 0.3937244454855804, 'r2': 0.1000516044162103},\n",
       "  'low': {'rmse': 0.7575166288242727, 'r2': -2.331326416215067},\n",
       "  'high': {'rmse': 0.7583287123668878, 'r2': -2.3384728347876615}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_week = rsh_yd_X[(rsh_yd_X[\"season\"] == 2025) & (rsh_yd_X[\"week\"] == 4)].dropna().reset_index(drop=True)\n",
    "current_week_X = current_week[rsh_yd_input_cols + def_input_cols].reset_index(drop=True)\n",
    "all_players_unique = all_players_df.drop_duplicates(\"player_id\")\n",
    "current_week = current_week.merge(all_players_unique[[\"player_name\",\"player_id\"]],\n",
    "                                  how=\"left\", on=\"player_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808884e",
   "metadata": {},
   "source": [
    "### Check Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pred_mean, pred_median, (pred_lo, pred_hi), y_draws = predict_from_fitted(idata, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dfb4a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Mean: 19.53405859471916\n",
      "R2 Mean: 0.5791772442435261\n",
      "RMSE Median: 19.53689934109476\n",
      "R2 Median: 0.5790548387908364\n",
      "RMSE Lo: 37.581563136541014\n",
      "R2 Lo: -0.5576286383380709\n",
      "RMSE Hi: 37.47903163607568\n",
      "R2 Hi: -0.5491410646426385\n"
     ]
    }
   ],
   "source": [
    "# using mean\n",
    "rmse_mean = root_mean_squared_error(y, pred_mean)\n",
    "r2_mean = r2_score(y, pred_mean)\n",
    "\n",
    "# using median\n",
    "rmse_median = root_mean_squared_error(y, pred_median)\n",
    "r2_median = r2_score(y, pred_median)\n",
    "\n",
    "# using lo\n",
    "rmse_lo = root_mean_squared_error(y, pred_lo)\n",
    "r2_lo = r2_score(y, pred_lo)\n",
    "\n",
    "#using hi\n",
    "rmse_hi = root_mean_squared_error(y, pred_hi)\n",
    "r2_hi = r2_score(y, pred_hi)\n",
    "\n",
    "print(f\"RMSE Mean: {rmse_mean}\")\n",
    "print(f\"R2 Mean: {r2_mean}\")\n",
    "print(f\"RMSE Median: {rmse_median}\")\n",
    "print(f\"R2 Median: {r2_median}\")\n",
    "print(f\"RMSE Lo: {rmse_lo}\")\n",
    "print(f\"R2 Lo: {r2_lo}\")\n",
    "print(f\"RMSE Hi: {rmse_hi}\")\n",
    "print(f\"R2 Hi: {r2_hi}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfeproj-oIABPDjj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
