{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4ab1a2",
   "metadata": {},
   "source": [
    "# NFL Fantasy Football Projection Model Using XGBoost\n",
    "\n",
    "This notebook presents a comprehensive workflow for building an NFL fantasy football projection model using a Bayesian Method. Data sources include Yahoo, Pro-Football Reference, SportsDataIO, and NFLVerse. The goal is to leverage advanced machine learning techniques and rich datasets to generate accurate player projections for fantasy football analysis and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5313a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: c:\\Users\\bengu\\Documents\\NFL Data Project\\clairvoyent-raven-sports-analysis\\src\n",
      "Sys Path Before: ['C:\\\\Users\\\\bengu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\python310.zip', 'C:\\\\Users\\\\bengu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\DLLs', 'C:\\\\Users\\\\bengu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib', 'C:\\\\Users\\\\bengu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj', '', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj\\\\lib\\\\site-packages', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\bengu\\\\.virtualenvs\\\\cfeproj-oIABPDjj\\\\lib\\\\site-packages\\\\Pythonwin']\n",
      "Inserting project root to sys.path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(\"Sys Path Before:\", sys.path)\n",
    "if project_root not in sys.path:\n",
    "    print(\"Inserting project root to sys.path\")\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Now import\n",
    "from data_api import SportsDataIO, Yahoo, PFR, POSITION_PLAYER_STAT_PROJECTION_DATA_DICT\n",
    "import utils\n",
    "import yahoo_helpers\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1806398",
   "metadata": {},
   "source": [
    "## Import and clean data from nflverse source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbca551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFLVERSE_DATA_PATH = r\"C:\\Users\\bengu\\Documents\\Sports Analysis Project\\clairvoyent-raven-sports-analysis\\data\\nfl_player_stats_cleaned.csv\"\n",
    "NFLVERSE_TEAMS_DATA_PATH = r\"C:\\Users\\bengu\\Documents\\Sports Analysis Project\\clairvoyent-raven-sports-analysis\\data\\nfl_team_stats.xlsx\"\n",
    "NFLVERSE_INJURIES_PATH = r\"C:\\Users\\bengu\\Documents\\Sports Analysis Project\\clairvoyent-raven-sports-analysis\\data\\nfl_injuries.xlsx\"\n",
    "NFLVERSE_DEPTH_CHART_PATH = r\"C:\\Users\\bengu\\Documents\\NFL Data Project\\clairvoyent-raven-sports-analysis\\data\\nfl_depth_charts.xlsx\"\n",
    "\n",
    "all_players_df = pd.read_csv(NFLVERSE_DATA_PATH)\n",
    "all_teams_df = pd.read_excel(NFLVERSE_TEAMS_DATA_PATH, engine=\"openpyxl\")\n",
    "injuries_df = pd.read_excel(NFLVERSE_INJURIES_PATH, engine=\"openpyxl\")\n",
    "depth_df = pd.read_excel(NFLVERSE_DEPTH_CHART_PATH, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d221fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "if \"gsis_id\" in injuries_df.columns:\n",
    "   injuries_df = injuries_df.rename({\"gsis_id\": \"player_id\"}, axis=1)\n",
    "\n",
    "filtered_injuries_df = injuries_df[[\"season\", \"week\", \"player_id\", \"report_status\", \"practice_status\"]]\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_categorical_injury = filtered_injuries_df[[\"report_status\", \"practice_status\"]]\n",
    "\n",
    "encoded_data = encoder.fit_transform(X_categorical_injury)\n",
    "\n",
    "encoded_feature_names = encoder.get_feature_names_out(X_categorical_injury.columns)\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoded_feature_names)\n",
    "\n",
    "filtered_injuries_df = pd.concat([filtered_injuries_df[[\"season\", \"week\", \"player_id\"]], encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7e0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"gsis_id\" in depth_df.columns:\n",
    "    filtered_depth_df = depth_df.rename({\"gsis_id\": \"player_id\"}, axis=1)\n",
    "\n",
    "filtered_depth_df = filtered_depth_df[[\"season\", \"week\", \"player_id\", \"depth_team\"]]\n",
    "filtered_depth_df = filtered_depth_df.dropna(subset=[\"season\", \"week\"])\n",
    "filtered_depth_df[\"week\"] = filtered_depth_df[\"week\"].astype(int)\n",
    "filtered_depth_df[\"season\"] = filtered_depth_df[\"season\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0414d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Merge depth chart information and injury information onto the all players data frame.\n",
    "\"\"\"\n",
    "\n",
    "all_players_df = all_players_df.merge(filtered_injuries_df, how=\"left\", on=[\"player_id\", \"season\", \"week\"])\n",
    "\n",
    "all_players_df = all_players_df.merge(filtered_depth_df, how=\"left\", on=[\"player_id\", \"season\", \"week\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa87c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill none values for depth chart with the average value.\n",
    "# Fill the injury encoded values with 0 because it's safe to assume that no injury occurred\n",
    "\n",
    "depth_mean = all_players_df[\"depth_team\"].mean()\n",
    "all_players_df[\"depth_team\"] = all_players_df[\"depth_team\"].fillna(depth_mean)\n",
    "all_players_df[encoded_feature_names] = all_players_df[encoded_feature_names].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7775d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_categories = {\n",
    "    \"standard\": {\n",
    "        \"player_id\",\n",
    "        \"player_name\",\n",
    "        \"position\",\n",
    "        \"position_group\",\n",
    "        \"season\",\n",
    "        \"week\",\n",
    "        \"season_type\",\n",
    "        \"team\",\n",
    "        \"opponent_team\",\n",
    "        \"pacr\",\n",
    "        \"report_status_Doubtful\",\n",
    "        \"report_status_Note\",\n",
    "        \"report_status_Out\",\n",
    "        \"report_status_Probable\",\n",
    "        \"report_status_Questionable\",\n",
    "        \"report_status_nan\",\n",
    "        \"practice_status_\\n    \",\n",
    "        \"practice_status_Did Not Participate In Practice\",\n",
    "        \"practice_status_Full Participation in Practice\",\n",
    "        \"practice_status_Limited Participation in Practice\",\n",
    "        \"practice_status_Note\",\n",
    "        \"practice_status_Out (Definitely Will Not Play)\",\n",
    "        \"depth_team\", \n",
    "    },\n",
    "    \"passing\": {\n",
    "        \"completions\",\n",
    "        \"attempts\",\n",
    "        \"passing_yards\",\n",
    "        \"passing_tds\",\n",
    "        \"passing_interceptions\",\n",
    "        \"sacks_suffered\",\n",
    "        \"sack_yards_lost\",\n",
    "        \"sack_fumbles\",\n",
    "        \"sack_fumbles_lost\",\n",
    "        \"passing_air_yards\",\n",
    "        \"passing_yards_after_catch\",\n",
    "        \"passing_first_downs\",\n",
    "        \"passing_epa\",\n",
    "        \"passing_cpoe\",\n",
    "        \"passing_2pt_conversions\",\n",
    "        \"carries\", # Include rushing stats for QBs\n",
    "        \"rushing_yards\",\n",
    "        \"rushing_tds\",\n",
    "        \"rushing_fumbles\",\n",
    "        \"rushing_fumbles_lost\",\n",
    "        \"rushing_first_downs\",\n",
    "        \"rushing_epa\",\n",
    "        \"rushing_2pt_conversions\",\n",
    "    },\n",
    "    \"rushing_and_receiving\": {\n",
    "        \"carries\",\n",
    "        \"rushing_yards\",\n",
    "        \"rushing_tds\",\n",
    "        \"rushing_fumbles\",\n",
    "        \"rushing_fumbles_lost\",\n",
    "        \"rushing_first_downs\",\n",
    "        \"rushing_epa\",\n",
    "        \"rushing_2pt_conversions\",\n",
    "        \"receptions\",\n",
    "        \"targets\",\n",
    "        \"receiving_yards\",\n",
    "        \"receiving_tds\",\n",
    "        \"receiving_fumbles\",\n",
    "        \"receiving_fumbles_lost\",\n",
    "        \"receiving_air_yards\",\n",
    "        \"receiving_yards_after_catch\",\n",
    "        \"receiving_first_downs\",\n",
    "        \"rushing_epa\",\n",
    "        \"rushing_2pt_conversions\",\n",
    "        \"receptions\",\n",
    "        \"targets\",\n",
    "        \"receiving_yards\",\n",
    "        \"receiving_tds\",\n",
    "        \"receiving_fumbles\",\n",
    "        \"receiving_fumbles_lost\",\n",
    "        \"receiving_air_yards\",\n",
    "        \"receiving_yards_after_catch\",\n",
    "        \"receiving_first_downs\",\n",
    "        \"receiving_epa\",\n",
    "        \"receiving_2pt_conversions\",\n",
    "        \"racr\",\n",
    "        \"target_share\",\n",
    "        \"air_yards_share\",\n",
    "        \"wopr\",\n",
    "    },\n",
    "    \"defense\": {\n",
    "        \"special_teams_tds\",\n",
    "        \"def_tackles_solo\",\n",
    "        \"def_tackles_with_assist\",\n",
    "        \"def_tackle_assists\",\n",
    "        \"def_tackles_for_loss\",\n",
    "        \"def_tackles_for_loss_yards\",\n",
    "        \"def_fumbles_forced\",\n",
    "        \"def_sacks\",\n",
    "        \"def_sack_yards\",\n",
    "        \"def_qb_hits\",\n",
    "        \"def_interceptions\",\n",
    "        \"def_interception_yards\",\n",
    "        \"def_pass_defended\",\n",
    "        \"def_tds\",\n",
    "        \"def_fumbles\",\n",
    "        \"def_safeties\",\n",
    "        \"misc_yards\",\n",
    "        \"fumble_recovery_own\",\n",
    "        \"fumble_recovery_yards_own\",\n",
    "        \"fumble_recovery_opp\",\n",
    "        \"fumble_recovery_yards_opp\",\n",
    "        \"fumble_recovery_tds\",\n",
    "        \"penalties\",\n",
    "    },\n",
    "    \"kicking\": {\n",
    "        \"fg_made\",\n",
    "        \"fg_att\",\n",
    "        \"fg_missed\",\n",
    "        \"fg_blocked\",\n",
    "        \"fg_long\",\n",
    "        \"fg_pct\",\n",
    "        \"fg_made_0_19\",\n",
    "        \"fg_made_20_29\",\n",
    "        \"fg_made_30_39\",\n",
    "        \"fg_made_40_49\",\n",
    "        \"fg_made_50_59\",\n",
    "        \"fg_made_60_\",\n",
    "        \"fg_missed_0_19\",\n",
    "        \"fg_missed_20_29\",\n",
    "        \"fg_missed_30_39\",\n",
    "        \"fg_missed_40_49\",\n",
    "        \"fg_missed_50_59\",\n",
    "        \"fg_missed_60_\",\n",
    "        \"fg_made_list\",\n",
    "        \"fg_missed_list\",\n",
    "        \"fg_blocked_list\",\n",
    "        \"fg_made_distance\",\n",
    "        \"fg_missed_distance\",\n",
    "        \"fg_blocked_distance\",\n",
    "        \"pat_made\",\n",
    "        \"pat_att\",\n",
    "        \"pat_missed\",\n",
    "        \"pat_blocked\",\n",
    "        \"pat_pct\",\n",
    "        \"gwfg_made\",\n",
    "        \"gwfg_att\",\n",
    "        \"gwfg_missed\",\n",
    "        \"gwfg_blocked\",\n",
    "        \"gwfg_distance\",\n",
    "    },\n",
    "    \"special_teams\": {\n",
    "        \"punt_returns\",\n",
    "        \"punt_return_yards\",\n",
    "        \"kickoff_returns\",\n",
    "        \"kickoff_return_yards\",\n",
    "    },\n",
    "}\n",
    "\n",
    "categories_positions = {\n",
    "    \"passing\": [\"QB\"],\n",
    "    \"rushing_and_receiving\": [\"RB\", \"WR\"],\n",
    "    # Not available \"kicking\": [\"K\"] \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f56736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish dataframes for each positional group, filter by position value\n",
    "def filter_by_positional_group(df, category_key_a, category_key_b=\"standard\") -> pd.DataFrame:\n",
    "    new_df = df.loc[:, list(column_categories[category_key_a] | column_categories[category_key_b])]\n",
    "    new_df = new_df[new_df[\"position\"].isin(categories_positions[category_key_a])]\n",
    "    return new_df.reset_index(drop=True)\n",
    "\n",
    "# Data of interest\n",
    "passing_df = filter_by_positional_group(all_players_df, \"passing\")\n",
    "rushing_and_receiving_df = filter_by_positional_group(all_players_df, \"rushing_and_receiving\")\n",
    "\n",
    "# Save in case\n",
    "defense_df = all_players_df.loc[:, list(column_categories[\"standard\"] | column_categories[\"defense\"])]\n",
    "kicking_df = all_players_df.loc[:, list(column_categories[\"standard\"] | column_categories[\"kicking\"])]\n",
    "specials_teams_df = all_players_df.loc[:, list(column_categories[\"standard\"] | column_categories[\"special_teams\"])]\n",
    "\n",
    "# Give the dataframes each an alias\n",
    "passing_df.alias = \"passing_df\"\n",
    "rushing_and_receiving_df.alias = \"rushing_and_receiving_df\"\n",
    "defense_df.alias = \"defense_df\"\n",
    "kicking_df.alias = \"kicking_df\"\n",
    "specials_teams_df.alias = \"specials_teams_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1c018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking passing_df for null values\n",
      "passing_df contains 0 null values.\n",
      "Checking rushing_and_receiving_df for null values\n",
      "rushing_and_receiving_df contains 0 null values.\n",
      "Checking defense_df for null values\n",
      "defense_df contains 0 null values.\n",
      "Checking kicking_df for null values\n",
      "kicking_df contains 0 null values.\n",
      "Checking specials_teams_df for null values\n",
      "specials_teams_df contains 0 null values.\n"
     ]
    }
   ],
   "source": [
    "for df in [passing_df, rushing_and_receiving_df, defense_df, kicking_df, specials_teams_df]:\n",
    "    null_values = 0\n",
    "    print(f\"Checking {df.alias} for null values\")\n",
    "    null_counts = df.isna().sum()\n",
    "\n",
    "    for column, count in zip(null_counts.index, null_counts):\n",
    "        if count != 0:\n",
    "            null_values += 1\n",
    "            print(f\"Column: {column} contains {count} null values.\")\n",
    "    \n",
    "    print(f\"{df.alias} contains {null_values} null values.\")\n",
    "\n",
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2840d92",
   "metadata": {},
   "source": [
    "### Implement and Apply Model\n",
    "\n",
    "Implement multiple linear regression models to predict multiple statistics for rushers and receivers. \n",
    "\n",
    "* Define the targets: rushing_yards, rushing_tds, receiving_yards, receiving_tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e81076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pacr', 'player_id', 'opponent_team', 'receiving_epa',\n",
       "       'rushing_fumbles', 'target_share', 'rushing_yards', 'carries',\n",
       "       'rushing_fumbles_lost', 'position_group', 'team', 'racr',\n",
       "       'receiving_yards', 'receptions', 'receiving_yards_after_catch',\n",
       "       'receiving_tds', 'season', 'receiving_fumbles', 'wopr',\n",
       "       'receiving_first_downs', 'rushing_2pt_conversions',\n",
       "       'receiving_air_yards', 'week', 'rushing_epa', 'position',\n",
       "       'air_yards_share', 'season_type', 'targets', 'rushing_first_downs',\n",
       "       'rushing_tds', 'receiving_fumbles_lost', 'receiving_2pt_conversions',\n",
       "       'player_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rushing_and_receiving_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68947e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect xs, and ys.\n",
    "Normalize data using Z-score normalization\n",
    "(val - mean_val) / standard_deviation\n",
    "\n",
    "Create 4 buckets, one for each statistical category.\n",
    "\n",
    "Prefix   | Stat Category\n",
    "-------------------------\n",
    "rsh_yd_ -> rushing_yards\n",
    "rsh_td_ -> rushing_tds\n",
    "rc_yd_  -> receiving_yards\n",
    "rc_td_  -> receiving_tds\n",
    "\"\"\"\n",
    "\n",
    "inputs = {\n",
    "    \"rsh_yd\": [\"rushing_tds\", \"rushing_yards\", \"rushing_fumbles_lost\", \"racr\", \"rushing_epa\", \"rushing_fumbles\", \"carries\", \"pacr\", \"rushing_first_downs\", \"rushing_2pt_conversions\"],\n",
    "    \"rsh_td\": [\"rushing_tds\", \"rushing_yards\", \"rushing_fumbles_lost\", \"racr\", \"rushing_epa\", \"rushing_fumbles\", \"carries\", \"pacr\", \"rushing_first_downs\", \"rushing_2pt_conversions\"],\n",
    "    \"rc_yd\" : [\"receiving_epa\", \"receiving_2pt_conversions\", \"racr\", \"air_yards_share\", \"receiving_tds\", \"receiving_first_downs\", \"wopr\", \"receiving_yards_after_catch\", \"receiving_air_yards\", \"target_share\", \"pacr\", \"targets\", \"receiving_yards\", \"receiving_fumbles_lost\", \"receptions\"],\n",
    "    \"rc_td\" : [\"receiving_epa\", \"receiving_2pt_conversions\", \"racr\", \"air_yards_share\", \"receiving_tds\", \"receiving_first_downs\", \"wopr\", \"receiving_yards_after_catch\", \"receiving_air_yards\", \"target_share\", \"pacr\", \"targets\", \"receiving_yards\", \"receiving_fumbles_lost\", \"receptions\"],\n",
    "    \"rc\": [\"receiving_epa\", \"receiving_2pt_conversions\", \"racr\", \"air_yards_share\", \"receiving_tds\", \"receiving_first_downs\", \"wopr\", \"receiving_yards_after_catch\", \"receiving_air_yards\", \"target_share\", \"pacr\", \"targets\", \"receiving_yards\", \"receiving_fumbles_lost\", \"receptions\"],\n",
    "    \"p_yd\": [\"completions\", \"attempts\", \"passing_yards\", \"passing_tds\", \"passing_interceptions\", \"sacks_suffered\", \"sack_yards_lost\", \"sack_fumbles\", \"sack_fumbles_lost\", \"passing_air_yards\", \"passing_yards_after_catch\", \"passing_first_downs\", \"passing_epa\", \"passing_cpoe\", \"passing_2pt_conversions\", \"pacr\"],\n",
    "    \"p_td\": [\"completions\", \"attempts\", \"passing_yards\", \"passing_tds\", \"passing_interceptions\", \"sacks_suffered\", \"sack_yards_lost\", \"sack_fumbles\", \"sack_fumbles_lost\", \"passing_air_yards\", \"passing_yards_after_catch\", \"passing_first_downs\", \"passing_epa\", \"passing_cpoe\", \"passing_2pt_conversions\", \"pacr\"],\n",
    "    \"intcpt\": [\"completions\", \"attempts\", \"passing_yards\", \"passing_tds\", \"passing_interceptions\", \"sacks_suffered\", \"sack_yards_lost\", \"sack_fumbles\", \"sack_fumbles_lost\", \"passing_air_yards\", \"passing_yards_after_catch\", \"passing_first_downs\", \"passing_epa\", \"passing_cpoe\", \"passing_2pt_conversions\", \"pacr\"],\n",
    "    \"rsh_fmbls\": [\"rushing_tds\", \"rushing_yards\", \"rushing_fumbles_lost\", \"racr\", \"rushing_epa\", \"rushing_fumbles\", \"carries\", \"pacr\", \"rushing_first_downs\", \"rushing_2pt_conversions\"],\n",
    "    \"rc_fmbls\": [\"receiving_epa\", \"receiving_2pt_conversions\", \"racr\", \"air_yards_share\", \"receiving_tds\", \"receiving_first_downs\", \"wopr\", \"receiving_yards_after_catch\", \"receiving_air_yards\", \"target_share\", \"pacr\", \"targets\", \"receiving_yards\", \"receiving_fumbles_lost\", \"receptions\"],\n",
    "    \"def\": [\"def_tackles_solo\", \"def_tackles_with_assist\", \"def_tackle_assists\", \"def_tackles_for_loss\", \"def_tackles_for_loss_yards\", \"def_fumbles_forced\", \"def_sacks\", \"def_sack_yards\", \"def_qb_hits\", \"def_interceptions\", \"def_interception_yards\", \"def_pass_defended\", \"def_tds\", \"def_fumbles\", \"def_safeties\"]\n",
    "}\n",
    "\n",
    "# Stat 1 rushing_yards\n",
    "rsh_yd_X = rushing_and_receiving_df[inputs[\"rsh_yd\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "# Stat 2 rushing_tds\n",
    "rsh_td_X = rushing_and_receiving_df[inputs[\"rsh_td\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "# Stat 3 receiving_yards\n",
    "rc_yd_X = rushing_and_receiving_df[inputs[\"rc_yd\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "# Stat 4 receiving_tds\n",
    "rc_td_X = rushing_and_receiving_df[inputs[\"rc_td\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "# Stat 5 receptions\n",
    "rc_X = rushing_and_receiving_df[inputs[\"rc\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "# Stat 6 passing_yards\n",
    "p_yd_X = passing_df[inputs[\"p_yd\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "# Stat 7 passing_tds\n",
    "p_td_X = passing_df[inputs[\"p_td\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "# Stat 8 interceptions\n",
    "intcpt_X = passing_df[inputs[\"intcpt\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "# Stat 9-10 fmbls\n",
    "rsh_fmbls_X = pd.concat([rushing_and_receiving_df, passing_df]).reset_index(drop=True)[inputs[\"rsh_fmbls\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "rc_fmbls_X = pd.concat([rushing_and_receiving_df, passing_df]).reset_index(drop=True)[inputs[\"rc_fmbls\"] + [\"season\", \"week\", \"player_id\", \"player_name\", \"opponent_team\", \"depth_team\"] + list(encoded_feature_names)]\n",
    "\n",
    "# Defensive stats for opponent\n",
    "defense_stats_df = all_teams_df[inputs[\"def\"] + [\"season\", \"week\", \"team\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeddce7",
   "metadata": {},
   "source": [
    "Calculate rolling data over a period of 3 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45e3ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_data(df: pd.DataFrame, sort_values: list, input_ref: str, groupby: list, rolling_period: int=3, min_periods: int=1, shift: int=1):\n",
    "    df = df.sort_values(sort_values)\n",
    "\n",
    "    df[[f\"{c}_roll{rolling_period}_shift\" for c in inputs[input_ref]]] = (\n",
    "        df.groupby(groupby)[inputs[input_ref]]\n",
    "         .transform(lambda x: x.rolling(rolling_period, min_periods=min_periods).mean().shift(shift))\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "rolling_period = 4\n",
    "\n",
    "rsh_yd_X = calculate_rolling_data(rsh_yd_X, [\"season\", \"week\", \"player_id\"], \"rsh_yd\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "rsh_td_X = calculate_rolling_data(rsh_td_X, [\"season\", \"week\", \"player_id\"], \"rsh_td\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "rc_yd_X = calculate_rolling_data(rc_yd_X, [\"season\", \"week\", \"player_id\"], \"rc_yd\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "rc_td_X = calculate_rolling_data(rc_td_X, [\"season\", \"week\", \"player_id\"], \"rc_td\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "rc_X = calculate_rolling_data(rc_X, [\"season\", \"week\", \"player_id\"], \"rc\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "p_yd_X = calculate_rolling_data(p_yd_X, [\"season\", \"week\", \"player_id\"], \"p_yd\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "p_td_X = calculate_rolling_data(p_td_X, [\"season\", \"week\", \"player_id\"], \"p_td\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "intcpt_X = calculate_rolling_data(intcpt_X, [\"season\", \"week\", \"player_id\"], \"intcpt\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "rsh_fmbls_X = calculate_rolling_data(rsh_fmbls_X, [\"season\", \"week\", \"player_id\"], \"rsh_fmbls\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "rc_fmbls_X = calculate_rolling_data(rc_fmbls_X, [\"season\", \"week\", \"player_id\"], \"rc_fmbls\", [\"season\", \"player_id\"], rolling_period=rolling_period)\n",
    "defense_stats_df = calculate_rolling_data(defense_stats_df, [\"season\", \"week\", \"team\"], \"def\", [\"season\", \"team\"], rolling_period=rolling_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d507348f",
   "metadata": {},
   "source": [
    "Normalize the data using Z-Score Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55348b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Z-Score Standardization (sklearn StandardScaler)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "rsh_yd_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"rsh_yd\"]] + [\"depth_team\"] + list(encoded_feature_names) \n",
    "rsh_td_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"rsh_td\"]] + [\"depth_team\"] + list(encoded_feature_names)\n",
    "rc_yd_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"rc_yd\"]] + [\"depth_team\"] + list(encoded_feature_names)\n",
    "rc_td_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"rc_td\"]] + [\"depth_team\"] + list(encoded_feature_names)\n",
    "rc_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"rc\"]] + [\"depth_team\"] + list(encoded_feature_names)\n",
    "p_yd_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"p_yd\"]] + [\"depth_team\"] + list(encoded_feature_names)\n",
    "p_td_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"p_td\"]] + [\"depth_team\"] + list(encoded_feature_names)\n",
    "intcpt_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"intcpt\"]] + [\"depth_team\"] + list(encoded_feature_names)\n",
    "rsh_fmbls_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"rsh_fmbls\"]] + [\"depth_team\"] + list(encoded_feature_names)\n",
    "rc_fmbls_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"rc_fmbls\"]] + [\"depth_team\"] + list(encoded_feature_names)\n",
    "def_input_cols = [col + f\"_roll{rolling_period}_shift\" for col in inputs[\"def\"]]\n",
    "\n",
    "scalers = {}\n",
    "\n",
    "def scale_inplace(df, cols, name):\n",
    "    # optionally: df = df.copy()  # if you want to avoid mutating the original\n",
    "    scaler = StandardScaler()\n",
    "    df.loc[:, cols] = scaler.fit_transform(df[cols])\n",
    "    scalers[name] = scaler\n",
    "    return df\n",
    "\n",
    "rsh_yd_X = scale_inplace(rsh_yd_X, rsh_yd_input_cols, \"rsh_yd\")\n",
    "rsh_td_X = scale_inplace(rsh_td_X, rsh_td_input_cols, \"rsh_td\")\n",
    "rc_yd_X = scale_inplace(rc_yd_X,  rc_yd_input_cols,  \"rc_yd\")\n",
    "rc_td_X = scale_inplace(rc_td_X,  rc_td_input_cols,  \"rc_td\")\n",
    "p_yd_X = scale_inplace(p_yd_X,  p_yd_input_cols,  \"p_yd\")\n",
    "p_td_X = scale_inplace(p_td_X,  p_td_input_cols,  \"p_td\")\n",
    "intcpt_X = scale_inplace(intcpt_X,  intcpt_input_cols,  \"intcpt\")\n",
    "rsh_fmbls_X = scale_inplace(rsh_fmbls_X, rsh_fmbls_input_cols, \"rsh_fmbls\")\n",
    "rc_fmbls_X = scale_inplace(rc_fmbls_X, rc_fmbls_input_cols, \"rc_fmbls\")\n",
    "defense_stats_df = scale_inplace(defense_stats_df, def_input_cols, \"def\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c71a4",
   "metadata": {},
   "source": [
    "Merge offense and defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fff7568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the defensive dataframe to the offensive one.\n",
    "rsh_yd_X = rsh_yd_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])\n",
    "rsh_td_X = rsh_td_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])\n",
    "rc_yd_X = rc_yd_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])\n",
    "rc_td_X = rc_td_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])\n",
    "rc_X = rc_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])\n",
    "p_yd_X = p_yd_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])\n",
    "p_td_X = p_td_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])\n",
    "intcpt_X = intcpt_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])\n",
    "rsh_fmbls_X = rsh_fmbls_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])\n",
    "rc_fmbls_X = rc_fmbls_X.merge(defense_stats_df, how=\"left\", left_on=[\"opponent_team\", \"season\", \"week\"], right_on=[\"team\", \"season\", \"week\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88debd",
   "metadata": {},
   "source": [
    "### Apply the Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac77e7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\pytensor\\link\\c\\cmodule.py:2968: UserWarning: PyTensor could not link to a BLAS installation. Operations that might benefit from BLAS will be severely degraded.\n",
      "This usually happens when PyTensor is installed via pip. We recommend it be installed via conda/mamba/pixi instead.\n",
      "Alternatively, you can use an experimental backend such as Numba or JAX that perform their own BLAS optimizations, by setting `pytensor.config.mode == 'NUMBA'` or passing `mode='NUMBA'` when compiling a PyTensor function.\n",
      "For more options and details see https://pytensor.readthedocs.io/en/latest/troubleshooting.html#how-do-i-configure-test-my-blas-library\n",
      "  warnings.warn(\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 6796 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 82\u001b[0m\n\u001b[0;32m     76\u001b[0m y \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()[target]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m X_train, X_valid, y_train, y_valid \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     79\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     80\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m model, y_obs, idata \u001b[38;5;241m=\u001b[39m \u001b[43mfit_bayesian_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m models[target] \u001b[38;5;241m=\u001b[39m model \n\u001b[0;32m     85\u001b[0m idatas[target] \u001b[38;5;241m=\u001b[39m idata\n",
      "Cell \u001b[1;32mIn[14], line 22\u001b[0m, in \u001b[0;36mfit_bayesian_model\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     19\u001b[0m mu \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m+\u001b[39m pm\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mdot(X, beta)\n\u001b[0;32m     20\u001b[0m y_obs \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, mu\u001b[38;5;241m=\u001b[39mmu, sigma\u001b[38;5;241m=\u001b[39msigma, observed\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m---> 22\u001b[0m idata \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, y_obs, idata\n",
      "File \u001b[1;32mc:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\pymc\\sampling\\mcmc.py:957\u001b[0m, in \u001b[0;36msample\u001b[1;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, compile_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[0;32m    955\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_return\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZarrTrace\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_sampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midata_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\pymc\\sampling\\mcmc.py:1042\u001b[0m, in \u001b[0;36m_sample_return\u001b[1;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m# Pick and slice chains to keep the maximum number of samples\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discard_tuned_samples:\n\u001b[1;32m-> 1042\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m \u001b[43m_choose_chains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\pymc\\backends\\base.py:624\u001b[0m, in \u001b[0;36m_choose_chains\u001b[1;34m(traces, tune)\u001b[0m\n\u001b[0;32m    622\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trace) \u001b[38;5;241m-\u001b[39m tune) \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces]\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths):\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough samples to build a trace.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    626\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(lengths)\n\u001b[0;32m    627\u001b[0m l_sort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lengths)[idxs]\n",
      "\u001b[1;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\"\"\"\n",
    "Build the model to project player yards for rushing and receiving.\n",
    "\"\"\"\n",
    "# df: one row per (player, week)\n",
    "# y = yards (float)\n",
    "# X = scaled features (numpy array), shape (n, p)\n",
    "\n",
    "def fit_bayesian_model(X, y):\n",
    "    with pm.Model() as model:\n",
    "        alpha = pm.Normal(\"alpha\", 0, 1)\n",
    "        beta = pm.Normal(\"beta\", 0, 1, shape=X.shape[1])\n",
    "        sigma = pm.HalfNormal(\"sigma\", 1)\n",
    "\n",
    "        mu = alpha + pm.math.dot(X, beta)\n",
    "        y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y)\n",
    "\n",
    "        idata = pm.sample()\n",
    "        return model, y_obs, idata\n",
    "    \n",
    "def predict_from_fitted(idata, X_new, predictive=True, ci=(5, 95), seed=0):\n",
    "    \"\"\"\n",
    "    Make predictions from your fitted Bayesian regression model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    idata : arviz.InferenceData\n",
    "        The posterior samples returned by pm.sample().\n",
    "    X_new : array-like of shape (n, p)\n",
    "        New feature matrix (must be scaled and ordered like training X).\n",
    "    predictive : bool\n",
    "        If True, return posterior predictive (includes noise).\n",
    "        If False, return posterior mean function (no added noise).\n",
    "    ci : tuple\n",
    "        Credible interval percentiles (default 90% CI).\n",
    "    seed : int\n",
    "        Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    Xn = np.asarray(X_new, dtype=float)\n",
    "\n",
    "    post = idata.posterior\n",
    "    alpha = post[\"alpha\"].values.reshape(-1)                  # (S,)\n",
    "    beta  = post[\"beta\"].values.reshape(-1, Xn.shape[1])      # (S, p)\n",
    "    sigma = post[\"sigma\"].values.reshape(-1)                  # (S,)\n",
    "\n",
    "    # Compute linear mean function draws (S,n)\n",
    "    mu_draws = beta @ Xn.T + alpha[:, None]\n",
    "\n",
    "    if predictive:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        y_draws = mu_draws + rng.normal(0.0, sigma[:, None], size=mu_draws.shape)\n",
    "    else:\n",
    "        y_draws = mu_draws\n",
    "\n",
    "    # Summaries\n",
    "    pred_mean   = y_draws.mean(axis=0)\n",
    "    pred_median = np.median(y_draws, axis=0)\n",
    "    lo, hi      = np.percentile(y_draws, ci, axis=0)\n",
    "\n",
    "    return pred_mean, pred_median, (lo, hi), y_draws\n",
    "\n",
    "model_results = {}\n",
    "idatas = {}\n",
    "models = {}\n",
    "\n",
    "input_dataframes = [rsh_yd_X, rsh_td_X, rc_yd_X, rc_td_X, rc_X, p_yd_X, p_td_X, intcpt_X, rsh_fmbls_X, rc_fmbls_X]  \n",
    "inputs = [rsh_yd_input_cols, rsh_td_input_cols, rc_yd_input_cols, rc_td_input_cols, rc_input_cols, p_yd_input_cols, p_td_input_cols, intcpt_input_cols, rsh_fmbls_input_cols, rc_fmbls_input_cols]\n",
    "targets = [\"rushing_yards\", \"rushing_tds\", \"receiving_yards\", \"receiving_tds\", \"receptions\", \"passing_yards\", \"passing_tds\", \"passing_interceptions\", \"rushing_fumbles_lost\", \"receiving_fumbles_lost\"]\n",
    "\n",
    "for df, input, target in zip(input_dataframes, inputs, targets):\n",
    "    X = df.dropna()[input + def_input_cols].reset_index(drop=True)\n",
    "    y = df.dropna()[target].reset_index(drop=True)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model, y_obs, idata = fit_bayesian_model(X_train, y_train)\n",
    "\n",
    "    models[target] = model \n",
    "    idatas[target] = idata\n",
    "\n",
    "    pred_mean, pred_median, (pred_lo, pred_hi), y_draws = predict_from_fitted(idata, X)\n",
    " \n",
    "    # using mean\n",
    "    rmse_mean = root_mean_squared_error(y, pred_mean)\n",
    "    r2_mean = r2_score(y, pred_mean)\n",
    "\n",
    "    # using median\n",
    "    rmse_median = root_mean_squared_error(y, pred_median)\n",
    "    r2_median = r2_score(y, pred_median)    \n",
    "\n",
    "    # using lo\n",
    "    rmse_lo = root_mean_squared_error(y, pred_lo)\n",
    "    r2_lo = r2_score(y, pred_lo)\n",
    "\n",
    "    #using hi\n",
    "    rmse_hi = root_mean_squared_error(y, pred_hi)  \n",
    "    r2_hi = r2_score(y, pred_hi)\n",
    "\n",
    "    model_results[target] = {\"mean\": {\"rmse\": rmse_mean, \"r2\": r2_mean}, \"median\": {\"rmse\": rmse_median, \"r2\": r2_median}, \"low\": {\"rmse\": rmse_lo, \"r2\": r2_lo}, \"high\": {\"rmse\": rmse_hi, \"r2\": r2_hi}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62021a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c2668f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rushing_yards': {'mean': {'rmse': 17.619336047816436, 'r2': 0.5927269139353224}, 'median': {'rmse': 17.620359498406494, 'r2': 0.592679598192539}, 'low': {'rmse': 33.97647673357516, 'r2': -0.5144792147908259}, 'high': {'rmse': 33.88928591623462, 'r2': -0.5067162410598429}}}\n"
     ]
    }
   ],
   "source": [
    "print(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808884e",
   "metadata": {},
   "source": [
    "### Check Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "SEASON = 2025\n",
    "WEEK = 4\n",
    "\n",
    "# Map dataframe names to their corresponding input-cols variable names\n",
    "datasets = {\n",
    "    \"rsh_yd_X\": \"rsh_yd_input_cols\",\n",
    "    \"rsh_td_X\": \"rsh_td_input_cols\",\n",
    "    \"rc_yd_X\":  \"rc_yd_input_cols\",\n",
    "    \"rc_td_X\":  \"rc_td_input_cols\",\n",
    "    \"rc_X\":     \"rc_input_cols\",\n",
    "    \"p_yd_X\":   \"p_yd_input_cols\",\n",
    "    \"p_td_X\":   \"p_td_input_cols\",\n",
    "    \"intcpt_X\": \"intcpt_input_cols\",\n",
    "    \"rsh_fmbls_X\": \"rsh_fmbls_input_cols\",\n",
    "    \"rc_fmbls_X\":  \"rc_fmbls_input_cols\",\n",
    "}\n",
    "\n",
    "for df_name, cols_name in datasets.items():\n",
    "    df = globals()[df_name]\n",
    "    # 1) filter to current week\n",
    "    cw_filtered = (\n",
    "        df[(df[\"season\"] == SEASON) & (df[\"week\"] == WEEK)]\n",
    "        .dropna()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    globals()[f\"cw_{df_name}\"] = cw_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb4a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Mean: 19.53405859471916\n",
      "R2 Mean: 0.5791772442435261\n",
      "RMSE Median: 19.53689934109476\n",
      "R2 Median: 0.5790548387908364\n",
      "RMSE Lo: 37.581563136541014\n",
      "R2 Lo: -0.5576286383380709\n",
      "RMSE Hi: 37.47903163607568\n",
      "R2 Hi: -0.5491410646426385\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "input_dataframes = [cw_rsh_yd_X, cw_rsh_td_X, cw_rc_yd_X, cw_rc_td_X, cw_rc_X, cw_p_yd_X, cw_p_td_X, cw_intcpt_X, cw_rsh_fmbls_X, cw_rc_fmbls_X]\n",
    "inputs = [rsh_yd_input_cols, rsh_td_input_cols, rc_yd_input_cols, rc_td_input_cols, rc_input_cols, p_yd_input_cols, p_td_input_cols, intcpt_input_cols, rsh_fmbls_input_cols, rc_fmbls_input_cols]\n",
    "targets = [\"rushing_yards\", \"rushing_tds\", \"receiving_yards\", \"receiving_tds\", \"receptions\", \"passing_yards\", \"passing_tds\", \"passing_interceptions\", \"rushing_fumbles_lost\", \"receiving_fumbles_lost\"]\n",
    "\n",
    "player_projections = defaultdict(dict)\n",
    "\n",
    "for df, input, target in zip(input_dataframes, inputs, targets):\n",
    "    X = df.dropna()[input + def_input_cols].reset_index(drop=True)\n",
    "    y = df.dropna()[target].reset_index(drop=True)\n",
    "\n",
    "    # Get the model from saved\n",
    "    reg = models[target]\n",
    "\n",
    "    # Evaluate\n",
    "    preds = reg.predict(X)\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        player_id, player_name = df.loc[i, \"player_id\"], df.loc[i, \"player_name\"]\n",
    "        if player_id not in player_projections:\n",
    "            player_projections[player_id][\"player_name\"] = player_name\n",
    "        \n",
    "        player_data = POSITION_PLAYER_STAT_PROJECTION_DATA_DICT[target].copy()\n",
    "        player_data[\"projection\"] = pred\n",
    "        player_data[\"true\"] = y.iloc[i]\n",
    "\n",
    "        player_projections[player_id][target] = player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a45656",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_4_projections = []\n",
    " \n",
    "for player_id, data in player_projections.items():\n",
    "    projected_points = 0\n",
    "    true_points = 0\n",
    "    for target in targets:\n",
    "        if target in data:\n",
    "            projected_points += data[target][\"projection\"] * data[target][\"weight\"]\n",
    "            true_points += data[target][\"true\"] * data[target][\"weight\"]\n",
    "\n",
    "    week_4_projections.append((data[\"player_name\"], projected_points, true_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f4624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = [x[2] for x in week_4_projections]\n",
    "preds = [x[1] for x in week_4_projections]\n",
    "\n",
    "error = root_mean_squared_error(true, preds)\n",
    "r2 = r2_score(true, preds)\n",
    "print(error, r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfeproj-oIABPDjj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
